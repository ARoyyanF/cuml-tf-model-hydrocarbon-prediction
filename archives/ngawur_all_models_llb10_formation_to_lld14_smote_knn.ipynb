{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bc54ff",
   "metadata": {
    "id": "60bc54ff"
   },
   "source": [
    "# Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93132d20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29494,
     "status": "ok",
     "timestamp": 1747242457367,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "93132d20",
    "outputId": "6f2187d6-df95-488b-dfdc-e86fe375ce56"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    is_running_on_colab = True\n",
    "except ImportError:\n",
    "    is_running_on_colab = False\n",
    "\n",
    "if is_running_on_colab:\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353b40e",
   "metadata": {
    "id": "c353b40e"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2a66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "start_notebook = time.time()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9d7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to generate mock data\n",
    "generate_mock_data = False # Set to True to generate mock data\n",
    "max_mock_depth_ft = 2000 # Define maximum depth for mock data\n",
    "well_name = \"LLB-10\"\n",
    "if not generate_mock_data:\n",
    "  if is_running_on_colab:\n",
    "    # Load data from Google Drive, if running on Google Colab\n",
    "    colab_repo_dir = \"/content/drive/MyDrive/riset-fttm-gdrive/cuml-tf-model-hydrocarbon-prediction\"\n",
    "    data = pd.read_csv(f\"{colab_repo_dir}/data/interpreted/interpreted_{well_name}.csv\", sep=',')\n",
    "  else:\n",
    "    # Load data from local directory\n",
    "    data = pd.read_csv(f\"./data/interpreted/interpreted_{well_name}.csv\", sep=',')\n",
    "if generate_mock_data:\n",
    "    print(f\"Generating mock data up to {max_mock_depth_ft} ft for well {well_name}...\")\n",
    "    mock_depth_step = 0.5\n",
    "    mock_dept_values = np.arange(0, max_mock_depth_ft, mock_depth_step)\n",
    "    num_mock_rows = len(mock_dept_values)\n",
    "\n",
    "    mock_data_dict = {'DEPT': mock_dept_values}\n",
    "\n",
    "    feature_cols_for_mock = ['CALI','DRHO','GR','MR','NPHI_corr','PEF','RHOB_CORR','ROP']\n",
    "\n",
    "    for col in feature_cols_for_mock:\n",
    "        mock_data_dict[col] = np.random.rand(num_mock_rows) * 100\n",
    "\n",
    "    mock_data_dict['hydrocarbon_formation_class'] = np.random.randint(0, 2, num_mock_rows)\n",
    "\n",
    "    data = pd.DataFrame(mock_data_dict)\n",
    "\n",
    "    print(f\"Mock data generated for well {well_name} with {num_mock_rows} rows and columns: {list(data.columns)}.\")\n",
    "    print(\"Mock data head:\")\n",
    "    print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a35b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[['DRHO','GR','MR','NPHI_corr','PEF','RHOB_CORR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a920c245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DRHO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI_corr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PEF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB_CORR",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "364d009b-de7f-497b-b0c2-3f2cecd3195b",
       "rows": [
        [
         "0",
         "0.051",
         "88.2",
         "0.875",
         "0.4841",
         "2.57",
         "2.103"
        ],
        [
         "1",
         "0.05",
         "85.65",
         "0.874",
         "0.4744",
         "2.582",
         "2.13"
        ],
        [
         "2",
         "0.064",
         "79.358",
         "0.9",
         "0.4845",
         "2.594",
         "2.177"
        ],
        [
         "3",
         "0.077",
         "74.004",
         "0.917",
         "0.5475",
         "2.613",
         "2.184"
        ],
        [
         "4",
         "0.081",
         "78.938",
         "0.973",
         "0.6065",
         "2.66",
         "2.142"
        ],
        [
         "5",
         "0.09",
         "86.457",
         "1.029",
         "0.5657",
         "2.695",
         "2.107"
        ],
        [
         "6",
         "0.114",
         "90.688",
         "1.033",
         "0.5111",
         "2.681",
         "2.129"
        ],
        [
         "7",
         "0.109",
         "88.285",
         "0.987",
         "0.5039",
         "2.647",
         "2.154"
        ],
        [
         "8",
         "0.07",
         "82.916",
         "0.961",
         "0.5204",
         "2.634",
         "2.141"
        ],
        [
         "9",
         "0.045",
         "76.724",
         "0.946",
         "0.5226",
         "2.648",
         "2.123"
        ],
        [
         "10",
         "0.057",
         "68.96",
         "0.931",
         "0.4925",
         "2.716",
         "2.126"
        ],
        [
         "11",
         "0.093",
         "62.631",
         "0.927",
         "0.4694",
         "2.825",
         "2.153"
        ],
        [
         "12",
         "0.111",
         "61.355",
         "0.943",
         "0.4719",
         "2.672",
         "2.158"
        ],
        [
         "13",
         "0.092",
         "66.933",
         "0.958",
         "0.4828",
         "2.109",
         "2.119"
        ],
        [
         "14",
         "0.083",
         "72.058",
         "0.966",
         "0.4876",
         "1.622",
         "2.094"
        ],
        [
         "15",
         "0.093",
         "74.38",
         "0.953",
         "0.4884",
         "1.547",
         "2.095"
        ],
        [
         "16",
         "0.087",
         "73.825",
         "0.94",
         "0.493",
         "1.676",
         "2.0855"
        ],
        [
         "17",
         "0.074",
         "73.598",
         "0.939",
         "0.5039",
         "1.737",
         "2.0748"
        ],
        [
         "18",
         "0.064",
         "72.056",
         "0.953",
         "0.5074",
         "1.685",
         "2.0769"
        ],
        [
         "19",
         "0.049",
         "68.912",
         "0.964",
         "0.475",
         "1.638",
         "2.0852"
        ],
        [
         "20",
         "0.032",
         "66.454",
         "0.984",
         "0.4499",
         "1.572",
         "2.0959"
        ],
        [
         "21",
         "0.019",
         "67.399",
         "1.004",
         "0.4491",
         "1.526",
         "2.106"
        ],
        [
         "22",
         "0.012",
         "70.86",
         "1.017",
         "0.4604",
         "1.569",
         "2.116"
        ],
        [
         "23",
         "0.014",
         "79.188",
         "1.008",
         "0.472",
         "1.593",
         "2.135"
        ],
        [
         "24",
         "0.011",
         "86.622",
         "1.0",
         "0.4594",
         "1.703",
         "2.148"
        ],
        [
         "25",
         "-0.001",
         "89.161",
         "0.996",
         "0.4581",
         "1.99",
         "2.139"
        ],
        [
         "26",
         "-0.009",
         "83.983",
         "0.968",
         "0.4711",
         "2.239",
         "2.1224"
        ],
        [
         "27",
         "0.0",
         "76.364",
         "0.94",
         "0.5208",
         "2.393",
         "2.1206"
        ],
        [
         "28",
         "0.033",
         "68.925",
         "0.934",
         "0.5256",
         "2.682",
         "2.14"
        ],
        [
         "29",
         "0.065",
         "64.664",
         "0.917",
         "0.4995",
         "2.992",
         "2.173"
        ],
        [
         "30",
         "0.073",
         "67.515",
         "0.909",
         "0.4687",
         "3.177",
         "2.191"
        ],
        [
         "31",
         "0.089",
         "76.475",
         "0.983",
         "0.4471",
         "3.355",
         "2.231"
        ],
        [
         "32",
         "0.119",
         "87.03",
         "1.034",
         "0.4364",
         "3.536",
         "2.288"
        ],
        [
         "33",
         "0.145",
         "90.293",
         "1.072",
         "0.4324",
         "3.593",
         "2.325"
        ],
        [
         "34",
         "0.153",
         "88.201",
         "1.111",
         "0.4252",
         "3.537",
         "2.327"
        ],
        [
         "35",
         "0.16",
         "80.949",
         "1.112",
         "0.4123",
         "3.569",
         "2.336"
        ],
        [
         "36",
         "0.16",
         "73.453",
         "1.138",
         "0.4102",
         "3.603",
         "2.333"
        ],
        [
         "37",
         "0.132",
         "64.655",
         "1.152",
         "0.4238",
         "3.386",
         "2.272"
        ],
        [
         "38",
         "0.116",
         "57.738",
         "1.13",
         "0.4304",
         "3.24",
         "2.239"
        ],
        [
         "39",
         "0.11",
         "52.676",
         "1.107",
         "0.4189",
         "3.146",
         "2.226"
        ],
        [
         "40",
         "0.102",
         "48.209",
         "1.104",
         "0.3961",
         "2.905",
         "2.214"
        ],
        [
         "41",
         "0.104",
         "43.943",
         "1.11",
         "0.3855",
         "2.424",
         "2.215"
        ],
        [
         "42",
         "0.102",
         "40.952",
         "1.115",
         "0.3876",
         "2.206",
         "2.228"
        ],
        [
         "43",
         "0.071",
         "44.441",
         "1.159",
         "0.3805",
         "2.243",
         "2.213"
        ],
        [
         "44",
         "0.044",
         "52.063",
         "1.203",
         "0.3836",
         "2.383",
         "2.211"
        ],
        [
         "45",
         "0.048",
         "60.663",
         "1.207",
         "0.3909",
         "2.477",
         "2.227"
        ],
        [
         "46",
         "0.065",
         "65.88",
         "1.244",
         "0.3969",
         "2.546",
         "2.272"
        ],
        [
         "47",
         "0.076",
         "67.899",
         "1.257",
         "0.3856",
         "2.523",
         "2.301"
        ],
        [
         "48",
         "0.077",
         "68.361",
         "1.261",
         "0.382",
         "2.356",
         "2.292"
        ],
        [
         "49",
         "0.08",
         "68.005",
         "1.264",
         "0.3877",
         "2.1",
         "2.275"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 7108
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRHO</th>\n",
       "      <th>GR</th>\n",
       "      <th>MR</th>\n",
       "      <th>NPHI_corr</th>\n",
       "      <th>PEF</th>\n",
       "      <th>RHOB_CORR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051</td>\n",
       "      <td>88.200</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.4841</td>\n",
       "      <td>2.570</td>\n",
       "      <td>2.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050</td>\n",
       "      <td>85.650</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064</td>\n",
       "      <td>79.358</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>2.594</td>\n",
       "      <td>2.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077</td>\n",
       "      <td>74.004</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.5475</td>\n",
       "      <td>2.613</td>\n",
       "      <td>2.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081</td>\n",
       "      <td>78.938</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>2.660</td>\n",
       "      <td>2.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>0.206</td>\n",
       "      <td>48.022</td>\n",
       "      <td>1.943</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>0.158</td>\n",
       "      <td>51.742</td>\n",
       "      <td>1.981</td>\n",
       "      <td>0.3199</td>\n",
       "      <td>3.960</td>\n",
       "      <td>2.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>0.089</td>\n",
       "      <td>54.041</td>\n",
       "      <td>2.015</td>\n",
       "      <td>0.3278</td>\n",
       "      <td>3.849</td>\n",
       "      <td>2.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>0.052</td>\n",
       "      <td>52.710</td>\n",
       "      <td>1.962</td>\n",
       "      <td>0.3315</td>\n",
       "      <td>3.949</td>\n",
       "      <td>2.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7107</th>\n",
       "      <td>0.059</td>\n",
       "      <td>49.641</td>\n",
       "      <td>1.948</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>4.067</td>\n",
       "      <td>2.434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7108 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DRHO      GR     MR  NPHI_corr    PEF  RHOB_CORR\n",
       "0     0.051  88.200  0.875     0.4841  2.570      2.103\n",
       "1     0.050  85.650  0.874     0.4744  2.582      2.130\n",
       "2     0.064  79.358  0.900     0.4845  2.594      2.177\n",
       "3     0.077  74.004  0.917     0.5475  2.613      2.184\n",
       "4     0.081  78.938  0.973     0.6065  2.660      2.142\n",
       "...     ...     ...    ...        ...    ...        ...\n",
       "7103  0.206  48.022  1.943     0.3222  4.039      2.595\n",
       "7104  0.158  51.742  1.981     0.3199  3.960      2.555\n",
       "7105  0.089  54.041  2.015     0.3278  3.849      2.477\n",
       "7106  0.052  52.710  1.962     0.3315  3.949      2.432\n",
       "7107  0.059  49.641  1.948     0.3218  4.067      2.434\n",
       "\n",
       "[7108 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b8005",
   "metadata": {
    "id": "804b8005"
   },
   "source": [
    "## Train/Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39bfef38",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747242463510,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "39bfef38"
   },
   "outputs": [],
   "source": [
    "# Misalkan 'data' adalah DataFrame Anda dan 'df' adalah fitur yang telah Anda ekstrak\n",
    "X = df  # Fitur\n",
    "y = data['hydrocarbon_formation_class']  # Label\n",
    "\n",
    "# Split data menjadi training dan testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089ac779",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1747242463535,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "089ac779",
    "outputId": "500520e0-ae46-4678-9d87-6e290c2924ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DRHO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI_corr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PEF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB_CORR",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a6cdb671-a94f-46c4-9bf8-43433d7494ff",
       "rows": [
        [
         "count",
         "5686.0",
         "5686.0",
         "5686.0",
         "5686.0",
         "5686.0",
         "5686.0"
        ],
        [
         "mean",
         "0.15376466180091453",
         "60.130491030601476",
         "1.4339183960604995",
         "0.41008784734435455",
         "2.9696909954273654",
         "2.346557228279986"
        ],
        [
         "std",
         "0.10319588534476981",
         "11.08057375471562",
         "1.0671128317222809",
         "0.052479336956864284",
         "0.702441983266646",
         "0.10954169151885623"
        ],
        [
         "min",
         "-0.196",
         "17.78",
         "0.561",
         "0.1367",
         "-0.202",
         "1.6204"
        ],
        [
         "25%",
         "0.091",
         "52.844750000000005",
         "1.09",
         "0.3829",
         "2.71825",
         "2.288"
        ],
        [
         "50%",
         "0.134",
         "62.1435",
         "1.226",
         "0.4085",
         "2.928",
         "2.353"
        ],
        [
         "75%",
         "0.187",
         "68.1295",
         "1.433",
         "0.442",
         "3.14975",
         "2.41"
        ],
        [
         "max",
         "0.93",
         "90.688",
         "24.142",
         "0.6239",
         "16.001",
         "3.433"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRHO</th>\n",
       "      <th>GR</th>\n",
       "      <th>MR</th>\n",
       "      <th>NPHI_corr</th>\n",
       "      <th>PEF</th>\n",
       "      <th>RHOB_CORR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5686.000000</td>\n",
       "      <td>5686.000000</td>\n",
       "      <td>5686.000000</td>\n",
       "      <td>5686.000000</td>\n",
       "      <td>5686.000000</td>\n",
       "      <td>5686.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.153765</td>\n",
       "      <td>60.130491</td>\n",
       "      <td>1.433918</td>\n",
       "      <td>0.410088</td>\n",
       "      <td>2.969691</td>\n",
       "      <td>2.346557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.103196</td>\n",
       "      <td>11.080574</td>\n",
       "      <td>1.067113</td>\n",
       "      <td>0.052479</td>\n",
       "      <td>0.702442</td>\n",
       "      <td>0.109542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.196000</td>\n",
       "      <td>17.780000</td>\n",
       "      <td>0.561000</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>-0.202000</td>\n",
       "      <td>1.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.091000</td>\n",
       "      <td>52.844750</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>2.718250</td>\n",
       "      <td>2.288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.134000</td>\n",
       "      <td>62.143500</td>\n",
       "      <td>1.226000</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>2.928000</td>\n",
       "      <td>2.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.187000</td>\n",
       "      <td>68.129500</td>\n",
       "      <td>1.433000</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>3.149750</td>\n",
       "      <td>2.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.930000</td>\n",
       "      <td>90.688000</td>\n",
       "      <td>24.142000</td>\n",
       "      <td>0.623900</td>\n",
       "      <td>16.001000</td>\n",
       "      <td>3.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DRHO           GR           MR    NPHI_corr          PEF  \\\n",
       "count  5686.000000  5686.000000  5686.000000  5686.000000  5686.000000   \n",
       "mean      0.153765    60.130491     1.433918     0.410088     2.969691   \n",
       "std       0.103196    11.080574     1.067113     0.052479     0.702442   \n",
       "min      -0.196000    17.780000     0.561000     0.136700    -0.202000   \n",
       "25%       0.091000    52.844750     1.090000     0.382900     2.718250   \n",
       "50%       0.134000    62.143500     1.226000     0.408500     2.928000   \n",
       "75%       0.187000    68.129500     1.433000     0.442000     3.149750   \n",
       "max       0.930000    90.688000    24.142000     0.623900    16.001000   \n",
       "\n",
       "         RHOB_CORR  \n",
       "count  5686.000000  \n",
       "mean      2.346557  \n",
       "std       0.109542  \n",
       "min       1.620400  \n",
       "25%       2.288000  \n",
       "50%       2.353000  \n",
       "75%       2.410000  \n",
       "max       3.433000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bd7ae",
   "metadata": {},
   "source": [
    "## Data Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733bd04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ac8e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data shape: (5686, 6) (5686,)\n",
      "Original training class distribution:\n",
      " hydrocarbon_formation_class\n",
      "0    5326\n",
      "1     360\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shape of training data after SMOTE: (10652, 6) (10652,)\n",
      "Class distribution after SMOTE:\n",
      " hydrocarbon_formation_class\n",
      "0    5326\n",
      "1    5326\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "# X_train and y_train are available from CELL INDEX 10\n",
    "print(\"Original training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Original training class distribution:\\n\", y_train.value_counts())\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nShape of training data after SMOTE:\", X_train_smote.shape, y_train_smote.shape)\n",
    "print(\"Class distribution after SMOTE:\\n\", y_train_smote.value_counts())\n",
    "\n",
    "# Update X_train and y_train to be the oversampled versions\n",
    "X_train = X_train_smote\n",
    "y_train = y_train_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fdf19b",
   "metadata": {
    "id": "33fdf19b"
   },
   "source": [
    "## Apply Quantile Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f4204b",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1747242463538,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "58f4204b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "def transform_quantile(X_train, X_test, X):\n",
    "    qt_transformer = QuantileTransformer(output_distribution='normal')\n",
    "    dfs = [X_train, X_test, X]\n",
    "    qt_dfs = [None,None,None]\n",
    "    for i, df in enumerate(dfs):\n",
    "        if (i == 0): #only perform fit_transform on training data\n",
    "            qt_dfs[i] = pd.DataFrame(qt_transformer.fit_transform(df))\n",
    "        else:\n",
    "            qt_dfs[i] = pd.DataFrame(qt_transformer.transform(df))\n",
    "        qt_dfs[i].columns = df.columns.values\n",
    "        qt_dfs[i].index = df.index.values\n",
    "    return qt_dfs[0], qt_dfs[1], qt_dfs[2] #X_train, X_test, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7681d51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1747242463627,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "b7681d51",
    "outputId": "4e078e43-691d-4bc9-f386-0ab02ec294f6"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X = transform_quantile(X_train, X_test, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2b3d1",
   "metadata": {
    "id": "32c2b3d1"
   },
   "source": [
    "## Feature Scaling\n",
    "\n",
    "karena menggunakan Quatile transformation dengan output gaussian, masing masing kolom secara otomatis ditransformasi ke distribusi normal baku, atau distribusi normal dengan rataan nol dan standar deviasi 1, oleh karena itu tidak diperlukan tambahan scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae6deec4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1747242463660,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "ae6deec4",
    "outputId": "c25f0a92-5697-4921-e73d-784fb07827d5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DRHO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "NPHI_corr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PEF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RHOB_CORR",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "28c51097-e2db-4baa-96fe-24fb032234b0",
       "rows": [
        [
         "count",
         "10652.0",
         "10652.0",
         "10652.0",
         "10652.0",
         "10652.0",
         "10652.0"
        ],
        [
         "mean",
         "0.0007526194427858914",
         "-0.0008294909312444138",
         "0.0027392847679373563",
         "-0.0010970681324325962",
         "0.0018729409235548904",
         "0.0031771958185264097"
        ],
        [
         "std",
         "0.9983245725859065",
         "1.000663756002231",
         "1.0012275128962727",
         "1.0009837077138881",
         "1.0035237239732002",
         "0.9983437568580182"
        ],
        [
         "min",
         "-5.199337582605575",
         "-5.199337582605575",
         "-5.199337582605575",
         "-5.199337582605575",
         "-5.199337582605575",
         "-5.199337582605575"
        ],
        [
         "25%",
         "-0.673497759449831",
         "-0.6712495201333397",
         "-0.671134559033525",
         "-0.6737405699917955",
         "-0.6759343121395658",
         "-0.6687625814303716"
        ],
        [
         "50%",
         "0.0013179455886344396",
         "-0.0016343203884538011",
         "0.0043347202807531475",
         "0.001821585979131219",
         "-0.00023727387170291577",
         "0.0056748042667197395"
        ],
        [
         "75%",
         "0.6768541480424047",
         "0.66637911042439",
         "0.6783638570547251",
         "0.672158692001583",
         "0.6800125783688009",
         "0.673702455413337"
        ],
        [
         "max",
         "5.19933758270342",
         "5.19933758270342",
         "5.19933758270342",
         "5.19933758270342",
         "5.19933758270342",
         "5.19933758270342"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRHO</th>\n",
       "      <th>GR</th>\n",
       "      <th>MR</th>\n",
       "      <th>NPHI_corr</th>\n",
       "      <th>PEF</th>\n",
       "      <th>RHOB_CORR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10652.000000</td>\n",
       "      <td>10652.000000</td>\n",
       "      <td>10652.000000</td>\n",
       "      <td>10652.000000</td>\n",
       "      <td>10652.000000</td>\n",
       "      <td>10652.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000753</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.003177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.998325</td>\n",
       "      <td>1.000664</td>\n",
       "      <td>1.001228</td>\n",
       "      <td>1.000984</td>\n",
       "      <td>1.003524</td>\n",
       "      <td>0.998344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "      <td>-5.199338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.673498</td>\n",
       "      <td>-0.671250</td>\n",
       "      <td>-0.671135</td>\n",
       "      <td>-0.673741</td>\n",
       "      <td>-0.675934</td>\n",
       "      <td>-0.668763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001318</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>0.005675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.676854</td>\n",
       "      <td>0.666379</td>\n",
       "      <td>0.678364</td>\n",
       "      <td>0.672159</td>\n",
       "      <td>0.680013</td>\n",
       "      <td>0.673702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "      <td>5.199338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DRHO            GR            MR     NPHI_corr           PEF  \\\n",
       "count  10652.000000  10652.000000  10652.000000  10652.000000  10652.000000   \n",
       "mean       0.000753     -0.000829      0.002739     -0.001097      0.001873   \n",
       "std        0.998325      1.000664      1.001228      1.000984      1.003524   \n",
       "min       -5.199338     -5.199338     -5.199338     -5.199338     -5.199338   \n",
       "25%       -0.673498     -0.671250     -0.671135     -0.673741     -0.675934   \n",
       "50%        0.001318     -0.001634      0.004335      0.001822     -0.000237   \n",
       "75%        0.676854      0.666379      0.678364      0.672159      0.680013   \n",
       "max        5.199338      5.199338      5.199338      5.199338      5.199338   \n",
       "\n",
       "          RHOB_CORR  \n",
       "count  10652.000000  \n",
       "mean       0.003177  \n",
       "std        0.998344  \n",
       "min       -5.199338  \n",
       "25%       -0.668763  \n",
       "50%        0.005675  \n",
       "75%        0.673702  \n",
       "max        5.199338  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1811d39",
   "metadata": {
    "id": "e1811d39"
   },
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de585b43",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747242463664,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "de585b43"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "sk_train_accuracy={}\n",
    "sk_test_accuracy={}\n",
    "\n",
    "cu_train_accuracy={}\n",
    "cu_test_accuracy={}\n",
    "\n",
    "sk_crossValidation_accuracy={}\n",
    "cu_crossValidation_accuracy={}\n",
    "\n",
    "sk_models = {} #sklearn models\n",
    "cu_models = {} #cuml models\n",
    "\n",
    "sk_times = {}\n",
    "cu_times = {}\n",
    "\n",
    "sk_pred = {}\n",
    "cu_pred = {}\n",
    "\n",
    "sk_pred_times = {}\n",
    "cu_pred_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02573183",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12770,
     "status": "ok",
     "timestamp": 1747242476436,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "02573183",
    "outputId": "7eefc600-b10a-469b-8416-7925762a9882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuML not found. Please ensure cuML is installed.\n"
     ]
    }
   ],
   "source": [
    "# test CuML availability & is working\n",
    "try:\n",
    "    import cuml\n",
    "    kmeans = cuml.KMeans(n_clusters=2)\n",
    "    # Create minimal dummy data\n",
    "    dummy_data = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8]])\n",
    "    kmeans.fit(dummy_data)\n",
    "    # Attempt to fit the model\n",
    "    has_cuml = True\n",
    "    print(\"cuML is found and working\")\n",
    "except ImportError:\n",
    "    has_cuml = False\n",
    "    print(\"cuML not found. Please ensure cuML is installed.\")\n",
    "except Exception as e:\n",
    "    has_cuml = False\n",
    "    print(f\"cuML couldn't be initialized or used. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4093261",
   "metadata": {
    "id": "b4093261"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1136f4d",
   "metadata": {
    "id": "b1136f4d"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb0c14c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1747242476437,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "cb0c14c7"
   },
   "outputs": [],
   "source": [
    "model_name = \"SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4016de5c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747242476437,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "4016de5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuML SVC not available. Please ensure cuML is installed and compatible with your environment.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SklearnSVC\n",
    "# Attempt to import cuML's SVC\n",
    "try:\n",
    "    from cuml.svm import SVC as cuMLSVC\n",
    "except ImportError:\n",
    "    print(\"cuML SVC not available. Please ensure cuML is installed and compatible with your environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9c77488",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8903,
     "status": "ok",
     "timestamp": 1747242485338,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "b9c77488",
    "outputId": "74364d55-0ca8-4f5d-81f3-73737ed3192c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "cuML is not installed or GPU not available. Please install RAPIDS cuML to run this benchmark.\n",
      "scikit-learn GridSearchCV training time (SVM) : 5.80 seconds\n",
      "scikit-learn Best parameters (SVM): {'C': 10, 'gamma': 'auto'}\n",
      "cuML is not installed or GPU not available. Please install RAPIDS cuML to run this benchmark.\n",
      "scikit-learn GridSearchCV training time (SVM) : 5.80 seconds\n",
      "scikit-learn Best parameters (SVM): {'C': 10, 'gamma': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for both models\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# 1) scikit-learn SVM with GridSearchCV\n",
    "sk_models[model_name] = GridSearchCV(\n",
    "    estimator=SklearnSVC(kernel='rbf'),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "sk_models[model_name].fit(X_train, y_train)\n",
    "time_end = time.time()\n",
    "sk_times[model_name] = time_end - time_start\n",
    "\n",
    "# 2) cuML SVM with the same GridSearchCV\n",
    "if has_cuml:\n",
    "    cu_models[model_name] = GridSearchCV(\n",
    "        estimator=cuMLSVC(kernel='rbf'),\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        verbose=3,\n",
    "        # Note: cuML estimator runs on GPU; this grid search runs on CPU orchestrating GPU calls\n",
    "        n_jobs=1  # avoid multiprocessing issues with GPU\n",
    "    )\n",
    "\n",
    "    time_start = time.time()\n",
    "    cu_models[model_name].fit(X_train, y_train)\n",
    "    time_end = time.time()\n",
    "    cu_times[model_name] = time_end - time_start\n",
    "    print(f\"cuml GridSearchCV training time ({model_name}) : {cu_times[model_name]:.2f} seconds\")\n",
    "    print(f\"cuml Best parameters ({model_name}): {cu_models[model_name].best_params_}\")\n",
    "else:\n",
    "    print(\"cuML is not installed or GPU not available. Please install RAPIDS cuML to run this benchmark.\")\n",
    "\n",
    "print(f\"scikit-learn GridSearchCV training time ({model_name}) : {sk_times[model_name]:.2f} seconds\")\n",
    "print(f\"scikit-learn Best parameters ({model_name}): {sk_models[model_name].best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4ebd3",
   "metadata": {
    "id": "f9e4ebd3"
   },
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4b59478",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1747242485349,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "d4b59478"
   },
   "outputs": [],
   "source": [
    "model_name = \"KNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "307602ed",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747242485351,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "307602ed"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as SklearnKNeighborsClassifier\n",
    "# Attempt to import cuML's KNeighborsClassifier\n",
    "try:\n",
    "    from cuml.neighbors import KNeighborsClassifier as cuMLKNeighborsClassifier\n",
    "    # has_cuml is already defined from SVM section, assuming if SVM cuml is available, KNN cuml is too.\n",
    "except ImportError:\n",
    "    # If cuML was previously found but KNN specific part is missing, update has_cuml for KNN context if necessary\n",
    "    # For simplicity, we rely on the initial has_cuml check. If specific components are missing,\n",
    "    # the cuML KNN block will be skipped or error out, which is acceptable.\n",
    "    # A more robust check could be:\n",
    "    # try: from cuml.svm import SVC as cuMLSVC; has_cuml_svm = True except: has_cuml_svm = False\n",
    "    # try: from cuml.neighbors import KNeighborsClassifier as cuMLKNeighborsClassifier; has_cuml_knn = True except: has_cuml_knn = False\n",
    "    pass # Rely on global has_cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "921e7503",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3458,
     "status": "ok",
     "timestamp": 1747242488815,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "921e7503",
    "outputId": "c906866e-3582-40d8-991f-342fbb0f262a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "cuML is not installed or GPU not available. Skipping cuML KNN benchmark.\n",
      "scikit-learn GridSearchCV training time (KNN) : 0.64 seconds\n",
      "scikit-learn Best parameters (KNN): {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "cuML is not installed or GPU not available. Skipping cuML KNN benchmark.\n",
      "scikit-learn GridSearchCV training time (KNN) : 0.64 seconds\n",
      "scikit-learn Best parameters (KNN): {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# 1) scikit-learn KNN with GridSearchCV\n",
    "sk_models[model_name] = GridSearchCV(\n",
    "    estimator=SklearnKNeighborsClassifier(),\n",
    "    param_grid=param_grid_knn,\n",
    "    cv=5,\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "sk_models[model_name].fit(X_train, y_train)\n",
    "time_end = time.time()\n",
    "sk_times[model_name] = time_end - time_start\n",
    "\n",
    "# 2) cuML KNN with the same GridSearchCV (adapted for cuML)\n",
    "if has_cuml:\n",
    "    try:\n",
    "        # Ensure cuMLKNeighborsClassifier was imported\n",
    "        cuMLKNeighborsClassifier\n",
    "\n",
    "        cu_models[model_name] = GridSearchCV(\n",
    "            estimator=cuMLKNeighborsClassifier(), # cuML KNN\n",
    "            param_grid=param_grid_knn, # Using the same grid, ensure params are compatible\n",
    "            cv=5,\n",
    "            verbose=3,\n",
    "            n_jobs=1 # Potentially can be >1 if managed carefully, but 1 is safer for GPU resources with GridSearchCV\n",
    "        )\n",
    "\n",
    "        time_start = time.time()\n",
    "        # cuML's KNN might prefer numpy arrays or cuDF dataframes\n",
    "        # X_train and y_train are pandas, which cuml usually handles.\n",
    "        # If issues arise, convert: X_train_cu = X_train.to_numpy(), y_train_cu = y_train.to_numpy()\n",
    "        cu_models[model_name].fit(X_train, y_train)\n",
    "        time_end = time.time()\n",
    "        cu_times[model_name] = time_end - time_start\n",
    "        print(f\"cuml GridSearchCV training time ({model_name}) : {cu_times[model_name]:.2f} seconds\")\n",
    "        print(f\"cuml Best parameters ({model_name}): {cu_models[model_name].best_params_}\")\n",
    "    except NameError: # handles if cuMLKNeighborsClassifier was not imported\n",
    "        print(f\"cuML KNeighborsClassifier not available. Skipping cuML {model_name} training.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during cuML {model_name} training: {e}\")\n",
    "        # Optionally, remove the model key if setup failed partway\n",
    "        if model_name in cu_models: del cu_models[model_name]\n",
    "        if model_name in cu_times: del cu_times[model_name]\n",
    "\n",
    "else:\n",
    "    print(f\"cuML is not installed or GPU not available. Skipping cuML {model_name} benchmark.\")\n",
    "\n",
    "print(f\"scikit-learn GridSearchCV training time ({model_name}) : {sk_times[model_name]:.2f} seconds\")\n",
    "print(f\"scikit-learn Best parameters ({model_name}): {sk_models[model_name].best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4127224",
   "metadata": {
    "id": "e4127224"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58222c34",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747242488819,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "58222c34"
   },
   "outputs": [],
   "source": [
    "model_name = \"RF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4a7ff61",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747242488834,
     "user": {
      "displayName": "2065_Ahmad Royyan Fatah",
      "userId": "06797199535233841376"
     },
     "user_tz": -420
    },
    "id": "e4a7ff61"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as SklearnRandomForestClassifier\n",
    "# Attempt to import cuML's RandomForestClassifier\n",
    "try:\n",
    "    from cuml.ensemble import RandomForestClassifier as cuMLRandomForestClassifier\n",
    "    # has_cuml is already defined, assuming if previous cuML models are available, RF is too.\n",
    "except ImportError:\n",
    "    # Pass, relying on global has_cuml. Specific check for cuMLRandomForestClassifier will happen in the training block.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57a872e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "cuML is not installed or GPU not available. Skipping cuML RF benchmark.\n",
      "scikit-learn GridSearchCV training time (RF) : 24.72 seconds\n",
      "scikit-learn Best parameters (RF): {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "cuML is not installed or GPU not available. Skipping cuML RF benchmark.\n",
      "scikit-learn GridSearchCV training time (RF) : 24.72 seconds\n",
      "scikit-learn Best parameters (RF): {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200], # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],    # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5], # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2],   # Minimum number of samples required to be at a leaf node\n",
    "    # 'max_features': ['auto', 'sqrt'] # Number of features to consider when looking for the best split (cuML might have different defaults/options)\n",
    "    # For cuML compatibility, specific parameters like 'max_features' might need adjustment or careful selection.\n",
    "    # cuML RandomForestClassifier has slightly different parameter names or accepted values for some arguments.\n",
    "    # e.g. max_features in cuML can be int, float, or 'auto' (auto is sqrt(n_features)).\n",
    "}\n",
    "\n",
    "# 1) scikit-learn RandomForest with GridSearchCV\n",
    "sk_models[model_name] = GridSearchCV(\n",
    "    estimator=SklearnRandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5, # Using 5-fold CV for RF due to potentially longer training times\n",
    "    verbose=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "sk_models[model_name].fit(X_train, y_train)\n",
    "time_end = time.time()\n",
    "sk_times[model_name] = time_end - time_start\n",
    "\n",
    "\n",
    "# 2) cuML RandomForest with GridSearchCV (adapted for cuML)\n",
    "if has_cuml:\n",
    "    try:\n",
    "        # Ensure cuMLRandomForestClassifier was imported\n",
    "        cuMLRandomForestClassifier\n",
    "\n",
    "        # cuML specific parameter adjustments if necessary.\n",
    "        # For example, cuML's RandomForestClassifier might not support all string options for max_features like sklearn.\n",
    "        # It typically supports int (number of features) or float (fraction of features). 'auto' is often sqrt(n_features).\n",
    "        # Let's use a simplified grid or ensure compatibility.\n",
    "        # The provided param_grid_rf should generally work if 'max_features' is omitted or set to a compatible value.\n",
    "\n",
    "        cu_models[model_name] = GridSearchCV(\n",
    "            estimator=cuMLRandomForestClassifier(random_state=42), # cuML RandomForest\n",
    "            param_grid=param_grid_rf, # Ensure parameters are compatible with cuML RF\n",
    "            cv=5, # Using 5-fold CV\n",
    "            verbose=3,\n",
    "            n_jobs=1 # Safer for GPU resources with GridSearchCV\n",
    "        )\n",
    "\n",
    "        time_start = time.time()\n",
    "        cu_models[model_name].fit(X_train, y_train) # X_train, y_train are pandas, cuML handles this\n",
    "        time_end = time.time()\n",
    "        cu_times[model_name] = time_end - time_start\n",
    "        print(f\"cuml GridSearchCV training time ({model_name}) : {cu_times[model_name]:.2f} seconds\")\n",
    "        print(f\"cuml Best parameters ({model_name}): {cu_models[model_name].best_params_}\")\n",
    "    except NameError:\n",
    "        print(f\"cuML RandomForestClassifier not available. Skipping cuML {model_name} training.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during cuML {model_name} training: {e}\")\n",
    "        if model_name in cu_models: del cu_models[model_name]\n",
    "        if model_name in cu_times: del cu_times[model_name]\n",
    "else:\n",
    "    print(f\"cuML is not installed or GPU not available. Skipping cuML {model_name} benchmark.\")\n",
    "\n",
    "print(f\"scikit-learn GridSearchCV training time ({model_name}) : {sk_times[model_name]:.2f} seconds\")\n",
    "print(f\"scikit-learn Best parameters ({model_name}): {sk_models[model_name].best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b12427",
   "metadata": {},
   "source": [
    "# Model Evaluation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_well_data(well_name, generate_mock_data=False, max_mock_depth_ft=2000, is_running_on_colab=False):\n",
    "    \"\"\"\n",
    "    Load well data for a given well name.\n",
    "    \n",
    "    Args:\n",
    "        well_name: Name of the well (e.g., 'LLD-14', 'LLB-10')\n",
    "        generate_mock_data: Boolean to generate mock data\n",
    "        max_mock_depth_ft: Maximum depth for mock data\n",
    "        is_running_on_colab: Boolean indicating if running on Google Colab\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with well data\n",
    "    \"\"\"\n",
    "    if not generate_mock_data:\n",
    "        if is_running_on_colab:\n",
    "            colab_repo_dir = \"/content/drive/MyDrive/riset-fttm-gdrive/cuml-tf-model-hydrocarbon-prediction\"\n",
    "            data = pd.read_csv(f\"{colab_repo_dir}/data/interpreted/interpreted_{well_name}.csv\", sep=',')\n",
    "        else:\n",
    "            data = pd.read_csv(f\"./data/interpreted/interpreted_{well_name}.csv\", sep=',')\n",
    "    else:\n",
    "        print(f\"Generating mock data up to {max_mock_depth_ft} ft for well {well_name}...\")\n",
    "        mock_depth_step = 0.5\n",
    "        mock_dept_values = np.arange(0, max_mock_depth_ft, mock_depth_step)\n",
    "        num_mock_rows = len(mock_dept_values)\n",
    "\n",
    "        mock_data_dict = {'DEPT': mock_dept_values}\n",
    "        feature_cols_for_mock = ['CALI','DRHO','GR','MR','NPHI_corr','PEF','RHOB_CORR','ROP']\n",
    "\n",
    "        for col in feature_cols_for_mock:\n",
    "            mock_data_dict[col] = np.random.rand(num_mock_rows) * 100\n",
    "\n",
    "        mock_data_dict['hydrocarbon_formation_class'] = np.random.randint(0, 2, num_mock_rows)\n",
    "        data = pd.DataFrame(mock_data_dict)\n",
    "\n",
    "    return data\n",
    "\n",
    "def prepare_well_features(data, feature_columns=['DRHO','GR','MR','NPHI_corr','PEF','RHOB_CORR']):\n",
    "    \"\"\"\n",
    "    Extract features and labels from well data.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with well data\n",
    "        feature_columns: List of feature column names\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (features_df, labels_series)\n",
    "    \"\"\"\n",
    "    features = data[feature_columns]\n",
    "    labels = data['hydrocarbon_formation_class']\n",
    "    return features, labels\n",
    "\n",
    "def apply_quantile_transformation_to_well(well_features, qt_transformer):\n",
    "    \"\"\"\n",
    "    Apply quantile transformation to well features using pre-fitted transformer.\n",
    "    \n",
    "    Args:\n",
    "        well_features: DataFrame with well features\n",
    "        qt_transformer: Pre-fitted QuantileTransformer\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with transformed features\n",
    "    \"\"\"\n",
    "    transformed_features = pd.DataFrame(qt_transformer.transform(well_features))\n",
    "    transformed_features.columns = well_features.columns.values\n",
    "    transformed_features.index = well_features.index.values\n",
    "    return transformed_features\n",
    "\n",
    "def evaluate_model_predictions(model, X_data, y_true, model_name, library_name, well_name, dataset_type):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions and return metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_data: Feature data\n",
    "        y_true: True labels\n",
    "        model_name: Name of the model (e.g., 'SVM', 'KNN')\n",
    "        library_name: Library name ('scikit-learn' or 'cuML')\n",
    "        well_name: Name of the well\n",
    "        dataset_type: Type of dataset ('train', 'test', 'external')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics and predictions\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    start_time = time.time()\n",
    "    if hasattr(X_data, 'to_numpy') and library_name == 'cuML':\n",
    "        y_pred = model.predict(X_data.to_numpy())\n",
    "    else:\n",
    "        y_pred = model.predict(X_data)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Convert cuPy arrays to NumPy if necessary\n",
    "    if hasattr(y_pred, 'get'):\n",
    "        y_pred = y_pred.get()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    pred_time = end_time - start_time\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'predictions': y_pred,\n",
    "        'accuracy': accuracy,\n",
    "        'prediction_time': pred_time,\n",
    "        'classification_report': class_report,\n",
    "        'confusion_matrix': cm,\n",
    "        'model_name': model_name,\n",
    "        'library_name': library_name,\n",
    "        'well_name': well_name,\n",
    "        'dataset_type': dataset_type\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(evaluation_result):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for evaluation result.\n",
    "    \n",
    "    Args:\n",
    "        evaluation_result: Dictionary from evaluate_model_predictions\n",
    "    \"\"\"\n",
    "    cm = evaluation_result['confusion_matrix']\n",
    "    model_name = evaluation_result['model_name']\n",
    "    library_name = evaluation_result['library_name']\n",
    "    well_name = evaluation_result['well_name']\n",
    "    dataset_type = evaluation_result['dataset_type']\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot()\n",
    "    plt.title(f\"{library_name} {model_name} - {well_name} ({dataset_type}) - Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def print_evaluation_summary(evaluation_result):\n",
    "    \"\"\"\n",
    "    Print summary of evaluation results.\n",
    "    \n",
    "    Args:\n",
    "        evaluation_result: Dictionary from evaluate_model_predictions\n",
    "    \"\"\"\n",
    "    print(f\"Model: {evaluation_result['library_name']} {evaluation_result['model_name']}\")\n",
    "    print(f\"Well: {evaluation_result['well_name']} ({evaluation_result['dataset_type']})\")\n",
    "    print(f\"Accuracy: {evaluation_result['accuracy']:.4f}\")\n",
    "    print(f\"Prediction Duration: {evaluation_result['prediction_time']:.4f} seconds\")\n",
    "    print(\"Classification Report:\")\n",
    "    class_report = evaluation_result['classification_report']\n",
    "    for class_name, metrics in class_report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            print(f\"  Class {class_name}: Precision={metrics['precision']:.3f}, Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the quantile transformer for later use\n",
    "# Re-create and fit the transformer to ensure it's available\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qt_transformer = QuantileTransformer(output_distribution='normal')\n",
    "qt_transformer.fit(X_train)\n",
    "\n",
    "print(\"Quantile transformer fitted and stored for evaluation.\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7434aa5",
   "metadata": {},
   "source": [
    "# Model Evaluation on Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c3d3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m evaluation_results = []\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get the quantile transformer from the earlier transformation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m qt_transformer = \u001b[43mtransform_quantile\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__defaults__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transform_quantile, \u001b[33m'\u001b[39m\u001b[33m__defaults__\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m qt_transformer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Re-create the transformer if not available\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantileTransformer\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Evaluate all models on training and test sets\n",
    "evaluation_results = []\n",
    "\n",
    "for model_name in sk_models.keys():\n",
    "    # Evaluate scikit-learn models\n",
    "    if model_name in sk_models:\n",
    "        # Training set evaluation\n",
    "        train_result_sk = evaluate_model_predictions(\n",
    "            sk_models[model_name], X_train, y_train, \n",
    "            model_name, 'scikit-learn', 'LLB-10', 'train'\n",
    "        )\n",
    "        evaluation_results.append(train_result_sk)\n",
    "        \n",
    "        # Test set evaluation\n",
    "        test_result_sk = evaluate_model_predictions(\n",
    "            sk_models[model_name], X_test, y_test, \n",
    "            model_name, 'scikit-learn', 'LLB-10', 'test'\n",
    "        )\n",
    "        evaluation_results.append(test_result_sk)\n",
    "        \n",
    "        print_evaluation_summary(train_result_sk)\n",
    "        print_evaluation_summary(test_result_sk)\n",
    "    \n",
    "    # Evaluate cuML models if available\n",
    "    if has_cuml and model_name in cu_models:\n",
    "        # Training set evaluation\n",
    "        train_result_cu = evaluate_model_predictions(\n",
    "            cu_models[model_name], X_train, y_train, \n",
    "            model_name, 'cuML', 'LLB-10', 'train'\n",
    "        )\n",
    "        evaluation_results.append(train_result_cu)\n",
    "        \n",
    "        # Test set evaluation\n",
    "        test_result_cu = evaluate_model_predictions(\n",
    "            cu_models[model_name], X_test, y_test, \n",
    "            model_name, 'cuML', 'LLB-10', 'test'\n",
    "        )\n",
    "        evaluation_results.append(test_result_cu)\n",
    "        \n",
    "        print_evaluation_summary(train_result_cu)\n",
    "        print_evaluation_summary(test_result_cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc93c5",
   "metadata": {},
   "source": [
    "# External Well Evaluation (LLD-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c68e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate on external well LLD-14\n",
    "external_well_name = \"LLD-14\"\n",
    "\n",
    "try:\n",
    "    # Load external well data\n",
    "    external_data = load_well_data(\n",
    "        external_well_name, \n",
    "        generate_mock_data=generate_mock_data,\n",
    "        max_mock_depth_ft=max_mock_depth_ft,\n",
    "        is_running_on_colab=is_running_on_colab\n",
    "    )\n",
    "    \n",
    "    # Prepare features and labels\n",
    "    external_features, external_labels = prepare_well_features(external_data)\n",
    "    \n",
    "    # Apply the same quantile transformation\n",
    "    external_features_transformed = apply_quantile_transformation_to_well(\n",
    "        external_features, qt_transformer\n",
    "    )\n",
    "    \n",
    "    print(f\"External well {external_well_name} data loaded successfully.\")\n",
    "    print(f\"Shape: {external_features_transformed.shape}\")\n",
    "    print(f\"Class distribution: {external_labels.value_counts()}\")\n",
    "    \n",
    "    # Evaluate all models on external well\n",
    "    for model_name in sk_models.keys():\n",
    "        # Evaluate scikit-learn models\n",
    "        if model_name in sk_models:\n",
    "            external_result_sk = evaluate_model_predictions(\n",
    "                sk_models[model_name], external_features_transformed, external_labels,\n",
    "                model_name, 'scikit-learn', external_well_name, 'external'\n",
    "            )\n",
    "            evaluation_results.append(external_result_sk)\n",
    "            print_evaluation_summary(external_result_sk)\n",
    "        \n",
    "        # Evaluate cuML models if available\n",
    "        if has_cuml and model_name in cu_models:\n",
    "            external_result_cu = evaluate_model_predictions(\n",
    "                cu_models[model_name], external_features_transformed, external_labels,\n",
    "                model_name, 'cuML', external_well_name, 'external'\n",
    "            )\n",
    "            evaluation_results.append(external_result_cu)\n",
    "            print_evaluation_summary(external_result_cu)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or evaluating external well {external_well_name}: {e}\")\n",
    "    print(\"Continuing with available evaluations...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c90f92",
   "metadata": {},
   "source": [
    "# Performance Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect performance metrics\n",
    "performance_data = []\n",
    "\n",
    "for result in evaluation_results:\n",
    "    performance_data.append({\n",
    "        'Model': result['model_name'],\n",
    "        'Library': result['library_name'],\n",
    "        'Well': result['well_name'],\n",
    "        'Dataset': result['dataset_type'],\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'Prediction_Time': result['prediction_time'],\n",
    "        'F1_Score': result['classification_report']['weighted avg']['f1-score']\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "print(\"Performance Summary:\")\n",
    "print(performance_df.round(4))\n",
    "\n",
    "# Plot accuracy comparison\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Subplot 1: Accuracy by Model and Library\n",
    "plt.subplot(2, 2, 1)\n",
    "for dataset in ['train', 'test', 'external']:\n",
    "    subset = performance_df[performance_df['Dataset'] == dataset]\n",
    "    if not subset.empty:\n",
    "        x_labels = [f\"{row['Model']}\\n{row['Library']}\" for _, row in subset.iterrows()]\n",
    "        plt.scatter(x_labels, subset['Accuracy'], label=dataset, alpha=0.7, s=100)\n",
    "\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Training Time Comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "training_times = []\n",
    "model_labels = []\n",
    "\n",
    "for model_name in sk_models.keys():\n",
    "    if model_name in sk_times:\n",
    "        training_times.append(sk_times[model_name])\n",
    "        model_labels.append(f\"{model_name}\\nscikit-learn\")\n",
    "    \n",
    "    if has_cuml and model_name in cu_times:\n",
    "        training_times.append(cu_times[model_name])\n",
    "        model_labels.append(f\"{model_name}\\ncuML\")\n",
    "\n",
    "if training_times:  # Only plot if we have data\n",
    "    plt.bar(model_labels, training_times, color=['skyblue', 'orange'] * len(sk_models))\n",
    "    plt.title('Training Time Comparison')\n",
    "    plt.ylabel('Training Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 3: Prediction Time Comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "test_data = performance_df[performance_df['Dataset'] == 'test']\n",
    "if not test_data.empty:\n",
    "    x_labels = [f\"{row['Model']}\\n{row['Library']}\" for _, row in test_data.iterrows()]\n",
    "    plt.bar(x_labels, test_data['Prediction_Time'], color='lightgreen')\n",
    "    plt.title('Prediction Time on Test Set')\n",
    "    plt.ylabel('Prediction Time (seconds)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 4: F1-Score Comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "for dataset in ['train', 'test', 'external']:\n",
    "    subset = performance_df[performance_df['Dataset'] == dataset]\n",
    "    if not subset.empty:\n",
    "        x_labels = [f\"{row['Model']}\\n{row['Library']}\" for _, row in subset.iterrows()]\n",
    "        plt.scatter(x_labels, subset['F1_Score'], label=dataset, alpha=0.7, s=100)\n",
    "\n",
    "plt.title('F1-Score Comparison')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01f0d6",
   "metadata": {},
   "source": [
    "# Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b463a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Training times summary\n",
    "print(\"\\nðŸ“Š TRAINING TIMES:\")\n",
    "print(\"-\" * 40)\n",
    "for model_name in sk_models.keys():\n",
    "    if model_name in sk_times:\n",
    "        print(f\"{model_name} (scikit-learn): {sk_times[model_name]:.2f} seconds\")\n",
    "    if has_cuml and model_name in cu_times:\n",
    "        print(f\"{model_name} (cuML): {cu_times[model_name]:.2f} seconds\")\n",
    "        if model_name in sk_times:\n",
    "            speedup = sk_times[model_name] / cu_times[model_name]\n",
    "            print(f\"  â†’ cuML speedup: {speedup:.2f}x\")\n",
    "\n",
    "# Best performing models\n",
    "print(\"\\nðŸ† BEST PERFORMING MODELS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Best on test set\n",
    "test_results = performance_df[performance_df['Dataset'] == 'test']\n",
    "if not test_results.empty:\n",
    "    best_test = test_results.loc[test_results['Accuracy'].idxmax()]\n",
    "    print(f\"Test Set: {best_test['Model']} ({best_test['Library']}) - Accuracy: {best_test['Accuracy']:.4f}\")\n",
    "\n",
    "# Best on external well\n",
    "external_results = performance_df[performance_df['Dataset'] == 'external']\n",
    "if not external_results.empty:\n",
    "    best_external = external_results.loc[external_results['Accuracy'].idxmax()]\n",
    "    print(f\"External Well: {best_external['Model']} ({best_external['Library']}) - Accuracy: {best_external['Accuracy']:.4f}\")\n",
    "\n",
    "# Cross-validation scores (if available)\n",
    "print(\"\\nðŸ“ˆ CROSS-VALIDATION SCORES:\")\n",
    "print(\"-\" * 40)\n",
    "for model_name in sk_models.keys():\n",
    "    if model_name in sk_models and hasattr(sk_models[model_name], 'best_score_'):\n",
    "        print(f\"{model_name} (scikit-learn): {sk_models[model_name].best_score_:.4f}\")\n",
    "    if has_cuml and model_name in cu_models and hasattr(cu_models[model_name], 'best_score_'):\n",
    "        print(f\"{model_name} (cuML): {cu_models[model_name].best_score_:.4f}\")\n",
    "\n",
    "# Total notebook execution time\n",
    "end_notebook = time.time()\n",
    "total_time = end_notebook - start_notebook\n",
    "print(f\"\\nâ±ï¸  TOTAL NOTEBOOK EXECUTION TIME: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
