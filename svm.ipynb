{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e101ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_notebook = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cuml\n",
    "import cupy as cp\n",
    "import cudf\n",
    "\n",
    "from scipy.stats import shapiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc21fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_name = \"LLB-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"/content/drive/MyDrive/riset-fttm-gdrive/cuml-tf-model-hydrocarbon-prediction/data/interpreted/interpreted_{well_name}.csv\", sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data[['CALI','DRHO','GR','MR','NPHI_corr','PEF','RHOB_CORR','ROP']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98111ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Struktur Data\n",
    "print(\"Dimensi DataFrame:\", data.shape)\n",
    "print(\"Kolom DataFrame:\", data.columns)\n",
    "print(\"Tipe Data:\", data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memeriksa Data yang Hilang\n",
    "print(\"\\nData yang Hilang:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistik Deskriptif\n",
    "print(\"\\nStatistik Deskriptif:\\n\", df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c039653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include=np.number).columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot histogram\n",
    "    sns.histplot(data[column], kde=False, bins=30, color='blue', alpha=0.6, label='Data Histogram')\n",
    "\n",
    "    # Tambahkan kurva normal\n",
    "    mean, std = data[column].mean(), data[column].std()\n",
    "    x = np.linspace(data[column].min(), data[column].max(), 1000)\n",
    "    y = norm.pdf(x, loc=mean, scale=std)\n",
    "    plt.plot(x, y * len(data[column]) * (data[column].max() - data[column].min()) / 30, color='red', label='Normal Curve')\n",
    "\n",
    "    # Label dan judul\n",
    "    plt.title(f'Distribusi {column}', fontsize=14)\n",
    "    plt.xlabel(column, fontsize=12)\n",
    "    plt.ylabel('Frekuensi', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b24126",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_results = df.apply(lambda col: shapiro(col)[1])  # [0] adalah p-value\n",
    "shapiro_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4560736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisasi Data\n",
    "\n",
    "\n",
    "boxplot_palette = sns.color_palette(\"Set2\", len(df.columns))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, palette=boxplot_palette)\n",
    "plt.title('Boxplot untuk Masing Masing Fitur')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(12, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (column, color) in enumerate(zip(df.columns, boxplot_palette)):\n",
    "    axes[i].boxplot(df[column], patch_artist=True, boxprops=dict(facecolor=color))\n",
    "    axes[i].set_title(f'Boxplot {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd5978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Korelasi\n",
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Matriks Korelasi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20432e8f",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1cc0a2",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misalkan 'data' adalah DataFrame Anda dan 'df' adalah fitur yang telah Anda ekstrak\n",
    "X = df  # Fitur\n",
    "y = data['hydrocarbon_formation_class']  # Label\n",
    "\n",
    "# Split data menjadi training dan testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02ab29",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e263127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_norm(dataframe,judul=''):\n",
    "  for column in dataframe.select_dtypes(include=np.number).columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot histogram\n",
    "    sns.histplot(dataframe[column], kde=False, bins=30, color='blue', alpha=0.6, label='Data Histogram')\n",
    "\n",
    "    # Tambahkan kurva normal\n",
    "    mean, std = dataframe[column].mean(), dataframe[column].std()\n",
    "    x = np.linspace(dataframe[column].min(), dataframe[column].max(), 1000)\n",
    "    y = norm.pdf(x, loc=mean, scale=std)\n",
    "    plt.plot(x, y * len(dataframe[column]) * (dataframe[column].max() - dataframe[column].min()) / 30, color='red', label='Normal Curve')\n",
    "\n",
    "    # Label dan judul\n",
    "    plt.title(f'Distribusi {column} {judul}', fontsize=14)\n",
    "    plt.xlabel(column, fontsize=12)\n",
    "    plt.ylabel('Frekuensi', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999888a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_norm(X_train,judul='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba8b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed62de",
   "metadata": {},
   "source": [
    "### Box-Cox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "\n",
    "tmp_X_bc=X_train.copy()\n",
    "\n",
    "lam = 0.3\n",
    "for column in tmp_X_bc.columns:\n",
    "  tmp_X_bc[column]=boxcox1p(tmp_X_bc[column],lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441cec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_norm(tmp_X_bc,judul='dengan Box-Cox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc00eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X_bc.apply(lambda col: shapiro(col)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332eeb9",
   "metadata": {},
   "source": [
    "### Yeo-Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf497a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "tmp_X_yj = X_train.copy()\n",
    "\n",
    "yj_transformer = PowerTransformer(method='yeo-johnson',standardize=False)\n",
    "yeo_johnson_data = pd.DataFrame(yj_transformer.fit_transform(tmp_X_yj))\n",
    "yeo_johnson_data.columns = tmp_X_yj.columns.values\n",
    "yeo_johnson_data.index = tmp_X_yj.index.values\n",
    "df_tf_temp = yeo_johnson_data\n",
    "for i in df_tf_temp.columns:\n",
    " tmp_X_yj[i]=df_tf_temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa296ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_norm(tmp_X_yj,judul='dengan Yeo-Johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a471dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X_yj.apply(lambda col: shapiro(col)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594cd60f",
   "metadata": {},
   "source": [
    "### Quantile Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c502ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "tmp_X_qt = X_train.copy()\n",
    "\n",
    "qt_transformer = QuantileTransformer(output_distribution='normal')\n",
    "qt_data = pd.DataFrame(qt_transformer.fit_transform(tmp_X_qt))\n",
    "qt_data.columns = tmp_X_qt.columns.values\n",
    "qt_data.index = tmp_X_qt.index.values\n",
    "df_tf_temp = qt_data\n",
    "for i in df_tf_temp.columns:\n",
    " tmp_X_qt[i]=df_tf_temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b84f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_norm(tmp_X_qt,judul='dengan Quantile Transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X_qt.apply(lambda col: shapiro(col)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295328be",
   "metadata": {},
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "trans_result=pd.DataFrame({'Kolom':df.columns})\n",
    "tmp_bc=[]\n",
    "tmp_yj=[]\n",
    "tmp_qt=[]\n",
    "for i in df.columns:\n",
    "  tmp_bc.append(skew(tmp_X_bc[i]))\n",
    "  tmp_yj.append(skew(tmp_X_yj[i]))\n",
    "  tmp_qt.append(skew(tmp_X_qt[i]))\n",
    "\n",
    "trans_result['Skewness setelah transformasi Box Cox']=tmp_bc\n",
    "trans_result['Skewness setelah transformasi Yeo Johnson']=tmp_yj\n",
    "trans_result['Skewness setelah transformasi Quantile']=tmp_qt\n",
    "trans_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "\n",
    "trans_result_kurtosis=pd.DataFrame({'Kolom':df.columns})\n",
    "tmp_bc=[]\n",
    "tmp_yj=[]\n",
    "tmp_qt=[]\n",
    "for i in df.columns:\n",
    "  tmp_bc.append(kurtosis(tmp_X_bc[i]))\n",
    "  tmp_yj.append(kurtosis(tmp_X_yj[i]))\n",
    "  tmp_qt.append(kurtosis(tmp_X_qt[i]))\n",
    "\n",
    "trans_result_kurtosis['Kurtosis setelah transformasi Box Cox']=tmp_bc\n",
    "trans_result_kurtosis['Kurtosis setelah transformasi Yeo Johnson']=tmp_yj\n",
    "trans_result_kurtosis['Kurtosis setelah transformasi Quantile']=tmp_qt\n",
    "trans_result_kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e529d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=tmp_X_qt\n",
    "\n",
    "X_test2 = pd.DataFrame(qt_transformer.transform(X_test))\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538fea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled2 = pd.DataFrame(qt_transformer.transform(X))\n",
    "X_scaled2.columns = X.columns.values\n",
    "X_scaled2.index = X.index.values\n",
    "X_scaled = X_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd85cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6c092",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df7f3f",
   "metadata": {},
   "source": [
    "karena menggunakan Quatile transformation dengan output gaussian, masing masing kolom secara otomatis ditransformasi ke distribusi normal baku, atau distribusi normal dengan rataan nol dan standar deviasi 1, oleh karena itu tidak diperlukan tambahan scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6868b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7293e",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa7a28",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8203f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_accuracy={}\n",
    "Test_accuracy={}\n",
    "CrossValidation_accuracy={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843df6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary CuML libraries for SVM and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d995453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.svm import SVC\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from cuml.dask.common.utils import persist_across_workers\n",
    "import cudf\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd235d",
   "metadata": {},
   "source": [
    "## SVM Model Training with Grid Search CV\n",
    "\n",
    "We'll implement Support Vector Machine using CuML's GPU-accelerated implementation and optimize hyperparameters using Grid Search Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4dd932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas DataFrames to cuDF for GPU processing\n",
    "X_train_gpu = cudf.DataFrame.from_pandas(X_train)\n",
    "X_test_gpu = cudf.DataFrame.from_pandas(X_test)\n",
    "y_train_gpu = cudf.Series(y_train.values)\n",
    "y_test_gpu = cudf.Series(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c5003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'degree': [2, 3, 4]  # Only used for poly kernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758dd9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual grid search implementation for CuML SVM\n",
    "def manual_grid_search_cv(X, y, param_grid, cv=5):\n",
    "    # Define our cross-validation splits\n",
    "    kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_combinations = []\n",
    "    for C in param_grid['C']:\n",
    "        for kernel in param_grid['kernel']:\n",
    "            for gamma in param_grid['gamma']:\n",
    "                if kernel == 'poly':\n",
    "                    for degree in param_grid['degree']:\n",
    "                        param_combinations.append({'C': C, 'kernel': kernel, 'gamma': gamma, 'degree': degree})\n",
    "                else:\n",
    "                    param_combinations.append({'C': C, 'kernel': kernel, 'gamma': gamma})\n",
    "    \n",
    "    # Run grid search\n",
    "    print(f\"Evaluating {len(param_combinations)} parameter combinations with {cv}-fold cross-validation\")\n",
    "    for params in tqdm(param_combinations):\n",
    "        cv_scores = []\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        for train_idx, val_idx in kfold.split(X.to_pandas(), y.to_pandas()):\n",
    "            X_cv_train = X.iloc[train_idx]\n",
    "            y_cv_train = y.iloc[train_idx]\n",
    "            X_cv_val = X.iloc[val_idx]\n",
    "            y_cv_val = y.iloc[val_idx]\n",
    "            \n",
    "            # Create and train model\n",
    "            model = SVC(**params)\n",
    "            model.fit(X_cv_train, y_cv_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred = model.predict(X_cv_val)\n",
    "            score = accuracy_score(y_cv_val, y_pred)\n",
    "            cv_scores.append(score)\n",
    "        \n",
    "        # Calculate mean CV score\n",
    "        mean_cv_score = sum(cv_scores) / len(cv_scores)\n",
    "        results.append({'params': params, 'mean_cv_score': mean_cv_score})\n",
    "        \n",
    "        # Update best parameters if needed\n",
    "        if mean_cv_score > best_score:\n",
    "            best_score = mean_cv_score\n",
    "            best_params = params\n",
    "    \n",
    "    return {'results': results, 'best_params': best_params, 'best_score': best_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid search\n",
    "start_time = time.time()\n",
    "print(\"Starting grid search cross-validation...\")\n",
    "grid_search_results = manual_grid_search_cv(X_train_gpu, y_train_gpu, param_grid, cv=5)\n",
    "print(f\"Grid search completed in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"Best parameters: {grid_search_results['best_params']}\")\n",
    "print(f\"Best cross-validation score: {grid_search_results['best_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "best_params = grid_search_results['best_params']\n",
    "print(\"Training final model with best parameters...\")\n",
    "final_model = SVC(**best_params)\n",
    "final_model.fit(X_train_gpu, y_train_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5937f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "# Training accuracy\n",
    "y_train_pred = final_model.predict(X_train_gpu)\n",
    "train_accuracy = accuracy_score(y_train_gpu, y_train_pred)\n",
    "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Test accuracy\n",
    "y_test_pred = final_model.predict(X_test_gpu)\n",
    "test_accuracy = accuracy_score(y_test_gpu, y_test_pred)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Store results in the existing dictionaries\n",
    "Train_accuracy['SVM'] = train_accuracy\n",
    "Test_accuracy['SVM'] = test_accuracy\n",
    "CrossValidation_accuracy['SVM'] = grid_search_results['best_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c08ba",
   "metadata": {},
   "source": [
    "## Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred.to_pandas()))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred.to_pandas())\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=sorted(y.unique()), \n",
    "            yticklabels=sorted(y.unique()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - SVM Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models (for when you have more models to compare)\n",
    "models_comparison = pd.DataFrame({\n",
    "    'Train Accuracy': Train_accuracy,\n",
    "    'Test Accuracy': Test_accuracy,\n",
    "    'CV Accuracy': CrossValidation_accuracy\n",
    "})\n",
    "\n",
    "models_comparison.sort_values(by='Test Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3514cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time\n",
    "end_notebook = time.time()\n",
    "print(f\"Total notebook execution time: {end_notebook - start_notebook:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
